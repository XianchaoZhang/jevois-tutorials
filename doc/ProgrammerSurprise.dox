/*! \page ProgrammerSurprise Surprise-based 监控摄像头

JeVois 可以直接处理来自其摄像头传感器的视频输入，并将结果记录到 microSD 中。在这里，我们将开发一个新模块，每当在视频流中检测到意外事件时，该模块都会录制一段简短的视频片段，以便将事件捕获到 microSD 中。这是标准基于运动的视频监控系统的增强版，该系统仅在物体移动时录制视频。此类系统的一个缺点是重复的运动（例如风中摇曳的树叶）很容易触发运动检测算法，并可能触发大量数据的记录。

本教程将向您展示如何 
----------------------------------

- 在 jevoisbase 中创建一个新的 JeVois 组件，以计算视频帧的意外情况
- 在 jevoisbase 中创建一个新的 JeVois 模块，以检测意外事件并为每个事件保存一个简短的视频片段到 microSD
- 首先在主机上编译、安装和测试
- 然后在 JeVois 智能相机上进行交叉编译、安装和测试
- 使用 jevois::Profiler 分析代码的执行情况
- 使用预先录制的视频来微调算法

这是一个相当长且详细的教程。为了让你兴奋，让我们先看看结果：这是一段长达一小时的监控视频。总体来说，它非常无聊，除了发生了一些简短的令人意外的事情（每次几秒钟）。你能找到它们吗？

\youtube{aSKncW7Jxrs}

这是我们在本教程中开发的 SurpriseRecorder 模块发现的结果（4 个真实事件加 2 个误报）：

\youtube{zIslIsHBfYw}

也就是说，它将 1 小时的视频总结为 6 个片段，每个片段大约 12 秒（减少了 50 倍：您只需观看一分钟多一点的令人意外的片段，而不是 1 小时的大部分无聊的镜头）。制作本教程结果视频后仔细检查，最后检测到的事件实际上似乎是一只鸟在视频帧上飞得非常快。因此，就意外而言，这实际上是结果视频中指出的命中而不是误报（即，这是一个令人意外的事件，尽管可能与监视目标无关 - 请参阅 [此处](https://www.ncbi.nlm.nih.gov/pubmed/28221085) 了解最近高度相关的相关性工作）。所以我们得到了 5 个命中和 1 个误报。据我们观看完整的一小时视频所知，没有遗漏，即我们的模块确实检测到了所有经过的船只（和鸟类）。一点也不差！

操作理论 
-------------------

我们将使用 Itti 和 Baldi 的意外理论来检测视频中的意外事件。

他们（首次）以正式、定量的方式对意外进行了定义，如下：如果观察结果显著影响观察者的内部（主观）信念，则该观察结果令人意外。例如，如果我相信今天有 10% 的降雨概率（我之前的信念），然后我向外看，只看到几朵小云，那么我可能仍然相信同样的 10% 的降雨概率（观察后的后验信念）。我的观察结果并不令人意外，Itti 和 Baldi 说这是因为它没有影响我的信念。正式地，当我观察后的后验信念与观察前的先验信念非常相似时，观察结果并不令人意外。相反，如果我看到天空到处都是阴云密布，我可能会将我的信念修改为今天有 80% 的降雨概率。由于我的后验信念现在与我之前的信念（80% 和 10% 的降雨概率）大不相同，因此观察云被认为具有很高的意外性。 Itti & Baldi 进一步详细说明了如何计算意外，即使用贝叶斯定理以原则性(principled)方式计算后验信念，并使用 Kullback-Leibler (KL) 散度来测量信念的后验分布和先验分布之间的差异。这产生了一种新的意外定量测量方法，其新单位是 \a wow （当您对某事的信念加倍时，您会体验到一次意外）。

欲了解更多信息，请参阅 [L. Itti, P. F. Baldi, Bayesian Surprise Attracts Human Attention, Vision Research, Vol. 49, No. 10, pp. 1295-1306, May 2009](http://ilab.usc.edu/publications/doc/Itti_Baldi09vr.pdf)

在这里，我们将：

- 抓取视频帧；

- 计算特征图和显著性图。这些将提供一定程度的不变性和对噪声的鲁棒性，这将产生比我们直接在 RGB 像素值上计算意外更稳定的整体结果（参见下一点）；

- 计算每个特征图的每个像素中的意外。这类似于 Itti & Baldi 所做的，但简化为在 JeVois 智能相机上实时运行。每个特征图中的每个像素都会随着时间的推移收集关于它通常在视频中该位置“看到”的内容的信念。当事物发生显着且令人意外的变化时，该像素将发出局部意外信号。因为意外比仅仅计算瞬时差异或测量当前观察是否只是学习分布的异常值更复杂，它将能够处理周期性运动（风中的树叶，水体上的涟漪），周期性闪烁（视野中不断闪烁的光）和噪音；

- 聚合为一个整体意外值（我们将简单取所有位置的最大值）；

- 当整体意外超过阈值时，我们将触发视频帧的录制。为了提供背景信息，我们将使用滚动帧缓冲区，以便始终录制每个意外事件前后 +/- 10 秒的视频；

- 因此，该模块的预期输出是记录到 microSD 的一系列短视频片段，每个发生的令人意外的事件一个片段。

该方法与 [R. C. Voorhies, L. Elazary, L. Itti, Neuromorphic Bayesian Surprise for Far Range Event Detection, In Proc 9th IEEE AVSS, Beijing, China, Sep 2012](http://ilab.usc.edu/publications/doc/Voorhies_etal12avss.pdf) 相关。

攻击计划 
--------------

- 我们将使用 jevoisbase 提供的 \ref Saliency 组件。

- 我们将使用类似于 jevoisbase 的 \ref SaveVideo 模块的方法来缓冲和保存视频帧到 MicroSD。

- 由于对 Saliency 的依赖，我们将在 jevoisbase 内部创建新模块。

- 我们首先将创建一个新组件来计算意外，该组件将使用 Saliency 作为子组件。虽然不是绝对必要的，但为我们的意外检测器创建一个组件将允许其他人轻松构建新模块，这些模块可以执行由意外触发的其他操作。

- 然后我们将为基于意外的视频录像机创建一个新的模块。

\note 由于本教程的结果预计对许多人有用，源代码已提交到 jevoisbase，因此本教程的所有代码都已在 jevoisbase 中。但是，本教程是在开发该代码时和提交之前编写的，以确保所有步骤都详细且有解释。


意外部分 
------------------

<ul>

<li>我们首先创建一个新组件并将其命名为 Surprise。由于它与 \ref Saliency 密切相关，我们将把它放在 <b>jevoisbase/include/jevoisbase/Components/Saliency/</b>（用于 .H 文件）和 <b>jevoisbase/src/Components/Saliency/</b>（用于 .C 文件）中，与 Saliency 组件一起。我们在这里需要 \b Surprise.H 和 \b Surprise.C ，以便我们组件的用户只需在自己的组件或模块中包含 \b Surprise.H 。通过将源代码放在 <b>jevoisbase/src/Components/</b> 下，我们确保 jevoisbase 构建规则 (CMake) 将自动检测它并将其编译成 \b Surprise.o ，它也将自动链接到包含 jevoisbase 所有组件的 \b libjevoisbase.so 库中。这是 jevoisbase 的 \b CMakeLists.txt 中以下行的结果：

\verbatim
jevois_setup_library(src/Components jevoisbase 1.0)
\endverbatim

它指示 CMake 从 <b>src/Components/</b> 下的所有源文件（递归）构建一个名为 \b libjevoisbase.so 的新库。 </li>

<li>我们用两个语句启动 \b Surprise.H ：
\code
#pragma once

#include <jevoisbase/Components/Saliency/Saliency.H>
\endcode

第一个命令告诉编译器如果该文件已经包含则不要再次包含，从而简化人们使用我们组件的方式（如果 \b Surprise.H 以某种方式被包含两次，他们不会收到有关重复定义的错误，可能是因为它被两个更高级别的组件使用，而这两个组件都用于一个更高级别的组件）。第二个命令允许我们在我们的组件中使用 \ref Saliency 组件。因为 \ref Saliency 已经是一个组件，所以包含 \b Saliency.H 将自动引入 JeVois 的整个组件、参数等机制，因此现在这里不需要进一步的包含语句。

<li>然后我们声明一个新类 \b Surprise ，它派生自 \ref jevois::Component 。我们没有将它放入任何命名空间，因为所有 jevoisbase 都位于全局命名空间中（它是最终用户代码）。在新组件的文档中，我们确保包含以下语句：

\verbatim
\ingroup components
\endverbatim 
这样我们的组件就会在 jevoisbase 在线文档中列在 jevoisbase 的所有组件下列出。

因此，我们这样开始：
\code
//! 计算视频帧上的 Itti & Baldi 意外
/*! 该组件使用 Itti & Baldi 的贝叶斯意外理论检测视频帧中的意外事件。

    [more doc ...]

    \ingroup components */
class Surprise : public jevois::Component
{
  public:
    //! Constructor
    Surprise(std::string const & instance);

    //! Virtual destructor for safe inheritance
    ~Surprise();
};
\endcode 
</li>

<li>请注意，我们的新组件 \b Surprise 并非继承 \b Saliency ，而是直接继承 \ref jevois::Component 。事实上，在 JeVois 框架中，我们使用组合来创建组件层次结构，而不是使用继承。这是为了避免可能与参数相关的模糊继承链（请记住，JeVois 组件从其所有参数继承，如 \ref parameter 中所述）。因此，\b Surprise 将包含一个 \b Saliency 子组件。

尽管 \ref jevois::Component 提供了查找函数来按名称查找子组件，但通常最好保留一个冗余但更直接的子组件句柄，以便我们经常使用。因此，我们在类中添加以下内容：

\code
  protected:
    std::shared_ptr<Saliency> itsSaliency;
\endcode

我们在构造函数中初始化它，而析构函数现在什么也不做。因此 \b Surprise.C 现在看起来像这样：

\code
Surprise::Surprise(std::string const & instance) :
    jevois::Component(instance)
{
  itsSaliency = addSubComponent<Saliency>("saliency");
}

Surprise::~Surprise()
{ }

\endcode


请注意，由于有了 JeVois 组件和参数框架，\b Saliency 的所有参数（用于尺度、不同特征的权重等）现在都已公开并可供 \b Surprise 用户访问，我们无需做任何工作。与使用具有许多参数的函数（例如在 OpenCV 中）相比，这是一个巨大的飞跃，OpenCV 需要我们在这里手动公开和转发所有这些参数。有关更多说明，请参阅 \ref jevois::Component 和 [JeVois 中的参数](/doc/classjevois_1_1Parameter_3_01Param_00_01Tail_8_8_8_4.html) 的文档。 </li>

<li>让我们运行 
\verbatim
./rebuild-host.sh
\endverbatim

现在从 <b>~/jevoisbase</b> 内部确保 CMake 检测到我们的新文件 <b>src/Components/Saliency/Surprise.H</b> 和 <b>src/Components/Saliency/Surprise.C</b> 并编译它们。

我们只需进行一次完全重建即可更新 CMake 缓存。稍后，当我们继续开发组件时，我们只需将目录更改为 \b hbuild ，然后简单地键入 \c make 即可重新编译我们更改的内容，而不是整个 \b jevoisbase 。

我们将首先为 \b host 全面开发和构建我们的新组件，这比为 JeVois ARM 处理器进行交叉编译更简单、更快捷。一旦主机上一切运行良好，我们将继续为平台硬件进行交叉编译。</li>


<li>现在开始实际工作：这里我们需要一个函数，该函数将接收视频帧并返回一个意外值，该意外值将是视频帧中最令人意外的位置的值。它将首先使用我们的 \ref Saliency 子组件计算显着性和特征图，然后在这些图上计算意外。我们建模或处理函数以匹配 \ref Saliency 中的函数之一，因为我们将直接将接收到的视频帧传递给 \ref Saliency 。因此，我们在 \b Surprise.H 中声明一个新的成员函数：

\code
    //! 从 YUYV 视频帧计算意外并返回意外值 wows
    double process(jevois::RawImage const & input);
\endcode

我们在 \b Surprise.C 中实现了它：

\code
double Surprise::process(jevois::RawImage const & input)
{
  // 计算特征图和显著性图，无要点。结果存储在 Saliency 类中：
  itsSaliency->process(input, false);

  // Compute surprise over the maps:
  double surprise = 0.0F;


  // TODO: add surprise computed over each feature map
  
  return surprise;
}
\endcode

注意，如果出现错误，Saliency::process() 可能会抛出异常。在这里，我们不必担心，因为我们没有分配任何资源，如果我们通过异常退出，这些资源可能会泄漏。有关更多信息，请参阅 \ref ModuleTips 。

此时在 <b>~/jevoisbase/hbuild/</b> 中输入 \c make 仍可以正常编译。 </li>

<li>根据 Itti & Baldi, 2009 的说法，我们在此假设泊松数据（来自代表特征值的神经元的尖峰 spikes from neurons representing the feature values），因此我们自然会使用 Gamma 共轭先验。在这些条件下，可以以封闭形式计算意外（参见 Itti & Baldi, 2009）。Gamma 分布有两个参数，alpha 和 beta - 它们基本上会在每个特征图中的每个像素处捕获我们对此特征像素通常看起来如何的信念。每次收到新的视频帧时，我们都会在此随时间更新此信念。如果给定的视频帧产生重大更新，我们将得出结论，刚刚发生了一些令人意外的事情。

为了计算 \ref Saliency 组件内的 salmap、intens、color、ori、flicker 和 motion 图的 surprise，我们需要存储两个相应的数组：一个用于先验 alpha，一个用于每个图的每个像素的先验 beta。然后，我们将逐个像素地更新这些数组，将 \ref Saliency 中的图视为新的数据观测值，并假设从 Saliency 组件收到的单个值代表泊松分布脉冲序列的平均值。然后，我们的先验 alpha 和 beta 数组将通过使用数据的贝叶斯更新变为后验 alpha 和 beta 数组，我们将根据先验和后验之间的 KL 散度计算 surprise。请注意（详情请参阅论文），我们选择 Gamma 先验可确保在使用泊松数据更新后，后验也是 Gamma（即 Gamma 是泊松的共轭先验）。然后，我们将当前帧的后验数组转移到我们类中存储的下一帧的先验数组中。

这里我们将为每个特征图中的每个像素独立计算意外。因此，不会利用显著性特征图的 2D 结构。我们需要 \b float 或 \b double 值来准确计算意外，让我们在这里使用浮点数。因此，我们可能只使用 <b>std::array<float></b> 将 alpha 和 beta 图存储为 1D 数组，但有一个细节除外：在第一个视频帧通过显著性处理之前，我们不知道特征图的大小。

因此我们需要动态大小的数组，我们能否只使用 <b>std::vector<float></b>。这比只使用原始 C 数组更好，因为当我们的组件被销毁时，vector 析构函数会自动释放内存，因此使用 <b>std::vector<float></b> 时，我们不必担心释放内存、异常、内存泄漏等问题，而使用原始 <b>float *</b> 和 \c new 和 \c delete 则不行。

最后要注意的一点是，map 原点对于此处的意外计算也不重要，我们将为每个 map 的每个像素独立计算意外。因此，我们可以将所有 map 的所有像素连接成一个数据向量，alpha 和 beta 也是如此。因此，我们在 \b protected 部分下将以下数据成员添加到我们的类中：

\code
    std::vector<float> itsAlpha, itsBeta;
\endcode

是的，我们可以使用成对的向量，或者创建一个辅助 auxiliary (alpha, beta) 结构，但使用 2 个向量访问速度可能更快。我们开始充实我们的 <b>process()</b> 函数，如下所示：

\code
float Surprise::process(jevois::RawImage const & input)
{
  float const updatefac = 0.95F; // 每个视频帧上的意外更新因子

  // 计算特征图和显著性图，无要点 gist。结果存储在 Saliency 类中：
  itsSaliency->process(input, false);

  // Compute surprise over the maps:
  float surprise = 0.0F;

  // 从所有 map 中聚合我们的数据值。这些 map 很小，无需并行化：
  std::vector<float> data;
  intg32 * pix = itsSaliency->salmap.pixels; size_t siz = env_img_size(&itsSaliency->salmap);
  for (size_t i = 0; i < siz; ++i) data.push_back(pix[i]);

  pix = itsSaliency->intens.pixels; siz = env_img_size(&itsSaliency->intens);
  for (size_t i = 0; i < siz; ++i) data.push_back(pix[i]);

  pix = itsSaliency->color.pixels; siz = env_img_size(&itsSaliency->color);
  for (size_t i = 0; i < siz; ++i) data.push_back(pix[i]);

  pix = itsSaliency->ori.pixels; siz = env_img_size(&itsSaliency->ori);
  for (size_t i = 0; i < siz; ++i) data.push_back(pix[i]);
 
  pix = itsSaliency->flicker.pixels; siz = env_img_size(&itsSaliency->flicker);
  for (size_t i = 0; i < siz; ++i) data.push_back(pix[i]);

  pix = itsSaliency->motion.pixels; siz = env_img_size(&itsSaliency->motion);
  for (size_t i = 0; i < siz; ++i) data.push_back(pix[i]);

  // 如果这是我们的第一帧，或者帧大小或 map 大小以某种方式发生了变化，则初始化先验。我们像 
  // iLab Neuromorphic C++ Vision Toolkit 的 SurpriseModelSP 一样初始化 alpha 和 beta，此实现源自该工具包。有关详细
  // 信息，另请参阅 Itti & Baldi，Vis Res，2009：
  if (itsAlpha.size() != data.size())
  {
    itsAlpha.clear(); itsBeta.clear();
    for (float d : data)
    {
      itsAlpha.push_back(d / (1.0F - updatefac));
      itsBeta.push_back(1.0F / (1.0F - updatefac));
    }
  }

  // more to come...
    
  return surprise;
}
\endcode
</li>

<li>此时我们意识到两件事：1) 更新因子 \b updatefac 可以作为我们组件的一个参数；2) 如果用户需要，我们是否可以同时计算 gist 向量上的意外？让我们添加这两个功能。首先是 \b updatefac 的一个参数：

在 \b Saliency.H 中，我们创建了一个命名空间 \b surprise ，用于存放参数。这是为了避免在给定的高级组件中可能联合使用的不同组件之间发生冲突（其他组件也可能有一个名为 \b updatefac 的参数）。这里的惯例是使用类名的小写版本作为其参数的命名空间名称。我们创建一个参数类别，这样当用户输入 \c help 时，所有参数都将分组在一起，请注意 \b \\relates 指令指示 doxygen 将参数与在线文档中的类相关联：

\code
namespace surprise
{
  static jevois::ParameterCategory const ParamCateg("Surprise Options");

  //! Parameter \relates Surprise
  JEVOIS_DECLARE_PARAMETER(updatefac, float, "Surprise update factor on every video frame", 0.95F,
                           jevois::Range<float>(0.001F, 0.999F), ParamCateg);

  //! Parameter \relates Surprise
  JEVOIS_DECLARE_PARAMETER(dogist, bool, "Include gist values in surprise computation", true, ParamCateg);
}
\endcode

请记住，\c JEVOIS_DECLARE_PARAMETER() 的格式为：
+ parameter name
+ parameter type
+ description
+ default value
+ 可选：有效值的指定；这里我们为 \b updatefac 指定了一个有效范围，而为 \b dogist 未指定任何内容。
+ 帮助消息中的分组类别。

然后我们将这两个参数添加到我们的组件中：

\code
float Surprise::process(jevois::RawImage const & input)
{
  // delete: float const updatefac = 0.95F; // surprise update factor on each video frame

  // ...
  itsSaliency->process(input, dogist::get());

  // ...
      itsAlpha.push_back(d / (1.0F - updatefac::get()));
      itsBeta.push_back(1.0F / (1.0F - updatefac::get()));

  // ...
\endcode

我们在 process 函数中使用它们：

\code
float Surprise::process(jevois::RawImage const & input)
{
  // delete: float const updatefac = 0.95F; // surprise update factor on each video frame

  // ...
  itsSaliency->process(input, dogist::get());

  // ...
      itsAlpha.push_back(d / (1.0F - updatefac::get()));
      itsBeta.push_back(1.0F / (1.0F - updatefac::get()));

  // ...
\endcode


就是这样。这些参数现在将出现在 \c help 消息中，用户将能够设置和获取它们的值，并且每个包含我们的 Surprise 组件作为子组件的组件或模块也将公开它们！

但请注意，对参数执行 \c get() 比仅获取变量的值稍微繁重一些，因为参数是线程安全的，因此在 get() 期间必须锁定互斥锁。因此，我们可以预先计算 divider，而不是为每个数据元素调用 \c updatefac::get()：

\code
  float const ufac = updatefac::get(); // get() 有点昂贵（需要互斥锁），因此在此处缓存。
  float const initfac = 1.0F / (1.0F - ufac);
 
  // ...
   
  if (itsAlpha.size() != datasiz)
  {
    itsAlpha.clear(); itsBeta.clear();
    for (float d : data)
    {
      itsAlpha.push_back(d * initfac);
      itsBeta.push_back(initfac);
    }
  }
\endcode

我们更新函数以将要点向量与数据连接起来：

\code
  // ...
  pix = itsSaliency->motion.pixels; siz = env_img_size(&itsSaliency->motion);
  for (size_t i = 0; i < siz; ++i) data.push_back(pix[i]);

  if (dogist::get())
  {
    unsigned char * g = itsSaliency->gist;
    for (size_t i = 0; i < itsSaliency->gist_size; ++i) data.push_back(g[i]);
  }
\endcode

快速 \c make ，所有仍然编译良好。由于 JeVois 的同步主机/平台开发环境，此时无需摆弄交叉编译器、microSD 卡等。
</li>

<li>好的，所以我们只需要计算意外，我们在这里按照 iLab Neuromorphic C++ Vision Toolkit 的 SurpriseModelSP 进行操作，我们的实现就是从中衍生出来的。另请参阅 Itti & Baldi，Vis Res，2009，了解详细信息：

\code
  size_t const datasiz = data.size(); // final data size

  // 为向量中的每个条目独立计算后验和 KL。这里我们假设泊松数据和 Gamma 共轭先验，如 Itti & Baldi, Vision Research, 2009
  // 中所述：
  for (size_t i = 0; i < datasiz; ++i)
  {
    // 首先，衰减 alpha 和 beta。确保 alpha 不会一直衰减到 0：
    float alpha = itsAlpha[i] * ufac, beta = itsBeta[i] * ufac;
    if (alpha < 1.0e-5F) alpha = 1.0e-5F;

    // 计算后验 posterior:
    float const newAlpha = alpha + val;
    float const newBeta  = beta  + 1.0F;

    // Surprise 是 KL(new || old)。跟踪在数据数组中找到的最大值：
    double const s = std::abs(KLgamma<double>(newAlpha, newBeta, alpha, beta, true));
    if (s > surprise) surprise = s;
    
    // 后验成为下一个视频帧的新先验：
    itsAlpha[i] = newAlpha; itsBeta[i] = newBeta;
  }

  // 返回在整个数据数组中找到的最大意外数量：
  return surprise;
\endcode

我们只需要实现辅助函数 \c KLgamma() 就大功告成了。这是 Gamma 先验上的意外的闭式解决方案。它最终使用了数百行不感兴趣的代码。我们只是从 Itti & Baldi 实现中撕下该代码。
</li>

<li>在完成组件之前，我们还有最后一个改进：除了布尔值 \p dogist ，如何让用户选择他们喜欢的频道或组合？我们将 \p dogist 替换为：

\code
  //! Parameter \relates Surprise
  JEVOIS_DECLARE_PARAMETER(channels, std::string, "Channels to use for surprise computation: any combination of "
                           "S (saliency), G (gist), C (color), I (intensity), O (orientation), F (flicker), and "
                           "M (motion). Duplicate letters will be ignored.",
                           "SCIOFMG", boost::regex("^[SCIOFMG]+$"), ParamCateg);
\endcode

正则表达式的有效值规范规定，我们需要一个仅由允许的字母组成且至少包含一个字母的字符串。我们修改类参数列表以使用此参数代替 \p dogist，并修改 \c process() 函数：

\code
float Surprise::process(jevois::RawImage const & input)
{
  std::string const chans = channels::get();

  // 计算特征图和显著性图，可能是要点。结果存储在 Saliency 类中：
  itsSaliency->process(input, (chans.find('G') != chans.npos));

  // 从所有 map 中聚合数据值。这些 map 很小，无需并行化：
  std::vector<float> data; std::string done;

  for (char c : chans)
  {
    if (done.find(c) != done.npos) continue; // skip duplicates
    done += c; // mark this channel as done
    intg32 * pix; size_t siz;

    switch (c)
    {
    case 'S': pix = itsSaliency->salmap.pixels; siz = env_img_size(&itsSaliency->salmap); break;
    case 'I': pix = itsSaliency->intens.pixels; siz = env_img_size(&itsSaliency->intens); break;
    case 'C': pix = itsSaliency->color.pixels; siz = env_img_size(&itsSaliency->color); break;
    case 'O': pix = itsSaliency->ori.pixels; siz = env_img_size(&itsSaliency->ori); break;
    case 'F': pix = itsSaliency->flicker.pixels; siz = env_img_size(&itsSaliency->flicker); break;
    case 'M': pix = itsSaliency->motion.pixels; siz = env_img_size(&itsSaliency->motion); break;
    case 'G':
    {
      unsigned char const * g = itsSaliency->gist;
      for (size_t i = 0; i < itsSaliency->gist_size; ++i) data.push_back(g[i]);
      continue;
    }
    default: continue; // 考虑到我们对参数的正则表达式规范，这种情况永远不会发生
    }

    // 如果数据不是要点，则连接数据：
    for (size_t i = 0; i < siz; ++i) data.push_back(pix[i]);
  }

  //...
\endcode
</li>

</ul>

我们已经完成了 Surprise 组件。最终代码位于 jevoisbase 的 Surprise.H 和 Surprise.C 中，除了在本教程编写后引入的一些小优化外，应该与我们上面开发的非常接近。\c KLgamma() 的详细信息也在其中。

SurpriseRecorder 模块 
-----------------------

我们现在准备开发一个新模块，我们将其称为 \b SurpriseRecorder 。它将计算意外事件并将检测到的每个意外事件的小视频片段记录到 microSD 中。

首先，我们：

<ul>

<li>创建目录 <b>jevoisbase/src/Modules/Sur​​priseRecorder</b> 并开始文件 <b>jevoisbase/src/Modules/Sur​​priseRecorder/SurpriseRecorder.C </b>

由于模块是终端实体（没有人会将它们用作子实体），我们通常以 Java 风格开发它们，即在单个 .C 文件中包含声明和实现。
</li>

<li>我们的模块将使用 Surprise 组件，因此我们将其引入。我们还包含来自 jevois 的 \b Module.H ：
\code
#include <jevois/Core/Module.H>
#include <jevoisbase/Components/Saliency/Surprise.H>
\endcode 
</li>

<li>我们以 JeVois 模块的形式开始我们的类。我们填写自定义 doxygen 标签，这些标签将用于生成模块的文档页面（参见 \ref ProgrammerSDK ）。

\code
//! Surprise-based recording of events
/*! 该模块检测来自摄像机的实时视频源中的意外事件，并记录每个检测到的事件的短视频片段。

    @author Laurent Itti

    @videomapping NONE 0 0 0 YUYV 640 480 15.0 JeVois SurpriseRecorder
    @email itti\@usc.edu
    @address University of Southern California, HNB-07A, 3641 Watt Way, Los Angeles, CA 90089-2520, USA
    @copyright Copyright (C) 2016 by Laurent Itti, iLab and the University of Southern California
    @mainurl http://jevois.org
    @supporturl http://jevois.org/doc
    @otherurl http://iLab.usc.edu
    @license GPL v3
    @distribution Unrestricted
    @restrictions None
    \ingroup modules */
class SurpriseRecorder : public jevois::Module
{
  public:

  // ...
\endcode

请注意，目前我们的目标是仅支持没有通过 USB 输出视频的模式。也就是说，该模块主要面向独立操作：让它运行一天，然后检查在 microSD 上录制的视频片段。不需要实时输出。因此，我们将覆盖 jevois::Module 的 \c process() 函数，该函数仅接受输入帧（而不接受输出帧）。jevois::Engine 将为来自相机传感器的每个新视频帧调用此函数。</li>

<li>有时，还要记得向模块中添加图标文件、一些屏幕截图等，如 \ref ProgrammerSDK 中所述</li>

<li>我们开始使用构造函数和析构函数以及 \c process() 函数的框架。我们的模块将使用 Surprise 子组件。我们不会忘记使用 JeVois 框架注册模块，以便可以在运行时将其加载到 JeVois 引擎中（请参阅最后一行和 \ref JEVOIS_REGISTER_MODULE() 宏）：

\code
class SurpriseRecorder : public jevois::Module
{
  public:
    // ####################################################################################################
    //! Constructor
    // ####################################################################################################
    SurpriseRecorder(std::string const & instance) : jevois::Module(instance)
    { itsSurprise = addSubComponent<Surprise>("surprise"); }

    // ####################################################################################################
    //! Virtual destructor for safe inheritance
    // ####################################################################################################
    virtual ~SurpriseRecorder()
    { }

    // ####################################################################################################
    //! Processing function, version with no video output
    // ####################################################################################################
    void process(jevois::InputFrame && inframe) override
    {
      // TODO
    }
    
  protected:
    std::shared_ptr<Surprise> itsSurprise;
};

// Allow the module to be loaded as a shared object (.so) file:
JEVOIS_REGISTER_MODULE(SurpriseRecorder);
\endcode
 </li>

<li>让我们尝试编译。与之前的组件一样，第一次添加新文件时，我们需要重新运行 CMake，只需运行完整的命令即可：

\verbatim
./rebuild-host.sh
\endverbatim

重建脚本将检测 <b>jevoisbase/src/Modules/</b> 下的新模块并将其添加到要构建的模块列表中。稍后，当我们继续编辑模块文件时，我们只需在 \b hbuild 目录中键入 \c make 即可。 </li>

<li>让我们添加一些参数。因为模块是终端实体，所以我们不需要将它们放在命名空间中。我们从 \ref SaveVideo 模块中汲取灵感：

\code
static jevois::ParameterCategory const ParamCateg("Surprise Recording Options");

#define PATHPREFIX "/jevois/data/surpriserecorder/"

//! Parameter \relates SurpriseRecorder
JEVOIS_DECLARE_PARAMETER(filename, std::string, "Name of the video file to write. If path is not absolute, "
                         PATHPREFIX " will be prepended to it. Name should contain a printf-like directive for "
                         "one int argument, which will start at 0 and be incremented on each streamoff command.",
                         "video%06d.avi", ParamCateg);

//! Parameter \relates SurpriseRecorder
JEVOIS_DECLARE_PARAMETER(fourcc, std::string, "FourCC of the codec to use. The OpenCV VideoWriter doc is unclear "
                         "as to which codecs are supported. Presumably, the ffmpeg library is used inside OpenCV. "
                         "Hence any video encoder supported by ffmpeg should work. Tested codecs include: MJPG, "
                         "MP4V, AVC1. Make sure you also pick the right filename extension (e.g., .avi for MJPG, "
                         ".mp4 for MP4V, etc)",
                         "MJPG", boost::regex("^\\w{4}$"), ParamCateg);

//! Parameter \relates SurpriseRecorder
JEVOIS_DECLARE_PARAMETER(fps, double, "Video frames/sec as stored in the file and to be used both for recording and "
                         "playback. Beware that the video writer will drop frames if you are capturing faster than "
                         "the frame rate specified here. For example, if capturing at 120fps, be sure to set this "
                         "parameter to 120, otherwise by default the saved video will be at 30fps even though capture "
                         "was running at 120fps.",
                         15.0, ParamCateg);

//! Parameter \relates SurpriseRecorder
JEVOIS_DECLARE_PARAMETER(thresh, float, "Surprise threshold. Lower values will record more events.",
                         5.0F, ParamCateg);

//! Parameter \relates SurpriseRecorder
JEVOIS_DECLARE_PARAMETER(ctxframes, unsigned int, "Number of context video frames recorded before and after "
                         "each surprising event.",
                         150, ParamCateg);
\endcode


并将它们添加到我们的模块类中：

\code
class SurpriseRecorder : public jevois::Module,
                         public jevois::Parameter<filename, fourcc, fps, thresh, ctxframes>
{
 // ...
\endcode 
</li>

<li>现在让我们看看如何记录帧。我们将使用与 SaveVideo 中类似的方法。但是，由于我们希望在每个意外事件之前和之后也保存上下文帧，因此这里的整体逻辑将有很大不同。因此，虽然人们一开始可能会想到将 SaveVideo 模块的视频保存方面拆分为一个可以共享的组件，但由于上下文引入的差异，我们不会在这里尝试这样做。记录上下文对于回顾意外事件的人来说很重要，因为有些事件可能只对几帧造成意外，因此如果没有事件前后几秒钟的额外上下文，观看起来会非常困难。

我们将采用以下基本攻击计划：

- 我们将启动一个线程来实际编码和保存视频。这是因为视频编码和将文件写入 microSD 的时间可能不可预测。因此，通过使用单独的线程执行此任务，我们可以确保主线程将保持以全速相机运行，并且即使磁盘缓存被刷新或某些帧需要很长时间才能压缩，也不会丢帧。

- 因此，我们需要启动一个线程。我们将在模块的 init() 期间执行此操作。为方便起见，我们的线程将运行我们类的成员函数，以便线程也可以访问我们所有的成员变量、参数等。

- 因此，在 \c process() 中我们将计算意外并决定是否应该保存当前帧。

- 我们需要一种线程安全的方式将帧从在主线程中运行的 \c process() 传送到我们的视频压缩和保存线程。我们将使用为此目的开发的 jevois::BounderBuffer<T> 。BoundedBuffer 是一个线程安全的生产者-消费者队列。我们的 \c process() 函数会将帧推送到其中，而我们的视频写入线程会从中弹出帧。

- 当我们的模块被销毁时，我们需要一种方法来告诉我们的线程停止。我们将使用 std::atomic<bool> 来实现这一点。此外，由于我们的 BoundedBuffer 将以阻塞模式使用，因此当我们想要退出时，我们的线程通常会在尝试 pop() 下一帧时被阻塞。因此，我们采用惯例，将空帧推入缓冲区将表示当前视频已完成。然后，写入线程将关闭文件并检查是否该退出了。

- 最后，我们需要处理上下文帧和细节，例如在上下文时间段内发生的几个意外事件，然后应将它们合并（例如，如果用户想要 10 秒的上下文，并且两个意外事件仅相隔 7 秒，那么我们最终应该得到一个视频，该视频在第一个事件开始前 10 秒开始，在第二个事件结束后 10 秒结束）。因此，我们将最后的 \p ctxframes 保存在另一个非线程安全的队列中，仅供主线程使用，以便它们随时准备在遇到意外事件时提供该事件之前的上下文。当意外事件开始时，我们会将所有这些帧传输到我们的 BoundedBuffer，除非我们已经保存了前一个事件。\c std::deque<cv::Mat> 应该非常适合，我们将其称为 \b itsCtxBuf 。请注意，由于 cv::Mat 只是像素数据的薄包装器，因此将 cv::Mat 推送到队列或将一堆 cv::Mat 从一个队列传输到另一个队列不会复制像素数据，只会复制 cv::Mat 中指向它的共享指针。因此移动这些图像的成本很低。


让我们从启动和停止线程开始。我们重写 jevois::Component::postInit() 来启动它，因为我们想要在启动时访问包含上下文框架数量的参数。此参数在构造时尚未设置，但在运行 postInit() 时将准备就绪。因此，同样，我们重写 jevois::Component::postUninit() 来停止它。

\code
    // ####################################################################################################
    //! Get started
    // ####################################################################################################
    void postInit() override
    {
      itsRunning.store(true);
      
      // Get our run() thread going, it is in charge of compressing and saving frames:
      itsRunFut = std::async(std::launch::async, &SurpriseRecorder::run, this);
    }

    // ####################################################################################################
    //! Get stopped
    // ####################################################################################################
    void postUninit() override
    {
      // Signal end of run:
      itsRunning.store(false);
      
      // Push an empty frame into our buffer to signal the end of video to our thread:
      itsBuf.push(cv::Mat());

      // Wait for the thread to complete:
      LINFO("Waiting for writer thread to complete, " << itsBuf.filled_size() << " frames to go...");
      try { itsRunFut.get(); } catch (...) { jevois::warnAndIgnoreException(); }
      LINFO("Writer thread completed. Syncing disk...");
      if (std::system("/bin/sync")) LERROR("Error syncing disk -- IGNORED");
      LINFO("Video " << itsFilename << " saved.");
    }


  // ...


  protected:
    void run() // Runs in a thread
    {
        // TODO
    }
    
    std::future<void> itsRunFut; //!< Future for our run() thread
    std::deque<cv::Mat> itsCtxBuf; //!< Buffer for context frames before event start
    jevois::BoundedBuffer<cv::Mat, jevois::BlockingBehavior::Block,
                          jevois::BlockingBehavior::Block> itsBuf; //!< Buffer for frames to save
    int itsToSave; //!< Number of context frames after end of event that remain to be saved
    int itsFileNum; //!< Video file number
    std::atomic<bool> itsRunning; //!< Flag to let run thread when to quit
    std::string itsFilename; //!< Currenf video file name
\endcode


我们还在构造函数中初始化一些同步变量：

\code
    SurpriseRecorder(std::string const & instance) : jevois::Module(instance), itsBuf(1000), itsToSave(0),
                                                     itsFileNum(0), itsRunning(false)
    {
       // ...
    }
\endcode

我们还需要了解 BoundedBuffer 以及我们将在 \c run() 和 \c process() 中使用的一些其他东西：

\code
#include <jevois/Types/BoundedBuffer.H>
#include <jevois/Image/RawImageOps.H>
#include <opencv2/videoio.hpp> // for cv::VideoCapture
#include <opencv2/imgproc.hpp> // for cv::rectangle()
#include <linux/videodev2.h> // for v4l2 pixel types
#include <fstream>
\endcode

在 \b hbuild 中快速输入 \c make 进行编译，不会出现任何错误或警告。 </li>


<li>现在让我们充实我们的 \c process() 函数：我们只需将帧转换为 cv::Mat 并将它们推送到我们的缓冲区中，然后计算意外。我们将使用异步线程并行执行这两项操作以进行意外计算：

\code
    void process(jevois::InputFrame && inframe) override
    {
       // Wait for next available camera image:
      jevois::RawImage inimg = inframe.get(); unsigned int const w = inimg.width, h = inimg.height;
      inimg.require("input", w, h, V4L2_PIX_FMT_YUYV); // accept any image size but require YUYV pixels

      // Compute surprise in a thread:
      std::future<double> itsSurpFut =
        std::async(std::launch::async, [&]() { return itsSurprise->process(inimg); } );

      // Convert the image to OpenCV BGR and push into our context buffer:
      cv::Mat cvimg = jevois::rawimage::convertToCvBGR(inimg);
      itsCtxBuf.push_back(cvimg);
      if (itsCtxBuf.size() > ctxframes::get()) itsCtxBuf.pop_front();
      
      // Wait until our surprise thread is done:
      double surprise = itsSurpFut.get(); // this could throw and that is ok

      // Let camera know we are done processing the raw input image:
      inframe.done();

      // If the current frame is surprising, check whether we are already saving. If so, just push the current frame for
      // saving and reset itsToSave to full context length (after the event). Otherwise, keep saving until the context
      // after the event is exhausted:
      if (surprise >= thresh::get())
      {
        // Draw a rectangle on surprising frames. Note that we draw it in cvimg but, since the pixel memory is shared
        // with the copy of it we just pushed into itsCtxBuf, the rectangle will get drawn in there too:
        cv::rectangle(cvimg, cv::Point(3, 3), cv::Point(w-4, h-4), cv::Scalar(0,0,255), 7);
        
        if (itsToSave)
        {
          // We are still saving the context after the previous event, just append our new event:
          itsBuf.push(cvimg);

          // Reset the number of frames we will save after the end of the event:
          itsToSave = ctxframes::get();
        }
        else
        {
          // Start of a new event. Dump the whole itsCtxBuf to the writer (it already contains the current frame):
          for (cv::Mat const & im : itsCtxBuf) itsBuf.push(im);

          // Initialize the number of frames we will save after the end of the event:
          itsToSave = ctxframes::get();
        }
      }
      else if (itsToSave)
      {
        // No more surprising event, but we are still saving the context after the last one:
        itsBuf.push(cvimg);

        // One more context frame after the last event was pushed for saving:
        --itsToSave;

        // Last context frame after the event was just pushed? If so, push an empty frame as well to close the current
        // video file. We will open a new file on the next surprising event:
        if (itsToSave == 0) itsBuf.push(cv::Mat());
      }
    }
\endcode


最后是我们的 \c run() 线程。事实证明，我们最终使用它时没有对 SaveVideo 进行任何修改。因此，实际上，我们可以将这个视频保存机制拆分成一个组件，供 SaveVideo 和 SurpriseRecorder 使用。我们将把它留到以后再做：


\code
    void run() // Runs in a thread
    {
      while (itsRunning.load())
      {
        // Create a VideoWriter here, since it has no close() function, this will ensure it gets destroyed and closes
        // the movie once we stop the recording:
        cv::VideoWriter writer;
        int frame = 0;
      
        while (true)
        {
          // Get next frame from the buffer:
          cv::Mat im = itsBuf.pop();

          // An empty image will be pushed when we are ready to close the video file:
          if (im.empty()) break;
        
          // Start the encoder if it is not yet running:
          if (writer.isOpened() == false)
          {
            // Parse the fourcc, regex in our param definition enforces 4 alphanumeric chars:
            std::string const fcc = fourcc::get();
            int const cvfcc = cv::VideoWriter::fourcc(fcc[0], fcc[1], fcc[2], fcc[3]);
          
            // Add path prefix if given filename is relative:
            std::string fn = filename::get();
            if (fn.empty()) LFATAL("Cannot save to an empty filename");
            if (fn[0] != '/') fn = PATHPREFIX + fn;

            // Create directory just in case it does not exist:
            std::string const cmd = "/bin/mkdir -p " + fn.substr(0, fn.rfind('/'));
            if (std::system(cmd.c_str())) LERROR("Error running [" << cmd << "] -- IGNORED");

            // Fill in the file number; be nice and do not overwrite existing files:
            while (true)
            {
              char tmp[2048];
              std::snprintf(tmp, 2047, fn.c_str(), itsFileNum);
              std::ifstream ifs(tmp);
              if (ifs.is_open() == false) { itsFilename = tmp; break; }
              ++itsFileNum;
            }
            
            // Open the writer:
            if (writer.open(itsFilename, cvfcc, fps::get(), im.size(), true) == false)
              LFATAL("Failed to open video encoder for file [" << itsFilename << ']');

            sendSerial("SAVETO " + itsFilename);
          }

          // Write the frame:
          writer << im;

          // Report what is going on once in a while:
          if ((++frame % 100) == 0) sendSerial("SAVEDNUM " + std::to_string(frame));
        }

        sendSerial("SAVEDONE " + itsFilename);

        // Our writer runs out of scope and closes the file here.
        ++itsFileNum;
      }
    }
\endcode


</li>

<li>最后一件事：因为我们目前还不知道会有什么意外值，所以让我们在每一帧上显示它们。我们添加一个简单的 \c LINFO() 消息，如下所示：

\code
      // Wait until our surprise thread is done:
      double surprise = itsSurpFut.get(); // this could throw and that is ok
      LINFO("surprise = " << surprise << " itsToSave = " << itsToSave);
\endcode


快速 \c make 并全部编译。输入 <code>sudo make install</code> 将编译后的模块安装到主机上的 <b>/jevois/</b> 目录中。测试时间到了！

</li>

</ul>

在主机上测试运行 
-----------------------------

让我们首先在主机上试用我们的新模块。我们将使用 YUYV 640x480 \@ 15 fps。

为了提供视频输入，让我们使用配置为 "dumb camera mode" 的 JeVois 相机：我们在 microSD 上添加视频映射，使其仅使用 PassThrough 模块输出 YUYV 640x480 \@ 15 fps（JeVois 上不进行处理）。然后我们将在主机上运行 \c jevois-daemon ，获取该格式的视频，并在主机上处理它：

<ul> 
<li>将此行添加到 JeVois 相机的 microSD 上的 <b>JEVOIS:/config/videomappings.cfg</b> 中：
\verbatim
YUYV 640 480 15.0 YUYV 640 480 15.0 JeVois PassThrough
\endverbatim

您的 JeVois 相机现在可以在该模式下作为哑相机运行。或者，您也可以使用常规网络摄像头提供输入，只要它支持此格式即可。</li>

<li>将您的 JeVois 相机连接到主机并允许其启动。</li>

<li>在主机上，确保您对 <b>/jevois/data/</b> 具有写入权限，然后键入
\verbatim
jevois-daemon
\endverbatim
以在主机处理器上运行 JeVois 处理。它可能会启动 DemoSaliency 作为默认处理模块。</li>

<li>要切换到我们的新模块，请在启动 \c jevois-daemon 的终端中输入以下内容：

\verbatim
streamoff
setmapping2 YUYV 640 480 15.0 JeVois SurpriseRecorder
setpar serout All
streamon
\endverbatim


你的终端应该显示以下几行：

\verbatim
streamoff
OK
setmapping2 YUYV 640 480 15.0 JeVois SurpriseRecorder
INF Engine::setFormatInternal: OUT: NONE 0x0 @ 0fps CAM: YUYV 640x480 @ 15fps MOD: JeVois:SurpriseRecorder
INF Camera::setFormat: Camera set video format to 640x480 YUYV
INF Engine::setFormatInternal: Instantiating dynamic loader for /jevois/modules/JeVois/SurpriseRecorder/SurpriseRecorder.so
OK
INF Engine::setFormatInternal: Module [SurpriseRecorder] loaded, initialized, and ready.
streamon
INF Camera::streamOn: 6 buffers of 614400 bytes allocated
OK
INF SurpriseRecorder::process: surprise = 0.00094728 itsToSave = 0
INF SurpriseRecorder::process: surprise = 1.44831e+07 itsToSave = 0
SAVETO /jevois/data/surpriserecorder/video000000.avi
INF SurpriseRecorder::process: surprise = 7.42191e+06 itsToSave = 150
INF SurpriseRecorder::process: surprise = 6.70748e+06 itsToSave = 149
INF SurpriseRecorder::process: surprise = 3.98372e+06 itsToSave = 148
INF SurpriseRecorder::process: surprise = 1.16248e+07 itsToSave = 147
INF SurpriseRecorder::process: surprise = 4.28625e+06 itsToSave = 150
INF SurpriseRecorder::process: surprise = 3.55222e+06 itsToSave = 149
INF SurpriseRecorder::process: surprise = 2.4415e+06 itsToSave = 148
INF SurpriseRecorder::process: surprise = 1.08243e+07 itsToSave = 147
INF SurpriseRecorder::process: surprise = 3.69354e+06 itsToSave = 150
INF SurpriseRecorder::process: surprise = 3.03062e+06 itsToSave = 149
INF SurpriseRecorder::process: surprise = 1.00832e+07 itsToSave = 148
INF SurpriseRecorder::process: surprise = 5.33606e+06 itsToSave = 150
[...]
\endverbatim

这些值非常大。首先，在摄像头前挥挥手，看看这些值。我们得到的值高于 1e7 wows（10 megawows）。所以让我们在那里设置阈值：

\verbatim
setpar thresh 1e7
\endverbatim

现在，10 秒后，您应该会看到有关视频文件已关闭的消息。挥挥手，就会打开一个新文件。\c LINFO() 现在变得很烦人，因此请将其从模块中删除，重新编译并再次运行，在启动 \c jevois-daemon 后输入以下内容：

\verbatim
streamoff
setmapping2 YUYV 640 480 15.0 JeVois SurpriseRecorder
setpar serout All
setpar thresh 1e7
setpar channels S
streamon
\endverbatim

现在，保持相机静止，不要看任何移动的东西。请注意，一个事件可能在开始时就被记录下来，这是因为前几帧令人意外（我们认为，这是由于在开始捕捉时相机上的一些初始增益控制），然后迅速变得无聊并停止记录。

每次在摄像头前挥手时，您都应该看到它将保存到一个新文件中。停止挥手 10 秒后，保存停止。

使用 \c mplayer 或类似程序播放写入 <b>/jevois/data/surpriserecorder/video*</b> 的视频。每个视频都应以 10 秒的空白开始，然后是挥手，再是 10 秒的空白。

</li>

</ul>

通过 Profiling 来确定运行速度 
--------------------------------------------

JeVois 框架提供了方便的 jevois::Timer 和 jevois::Profiler 类，可帮助您测量每帧执行操作所需的时间。这将帮助我们决定应该为我们的意外录像机建议什么标准的视频映射。这两个类的操作方式相同：

- 在每一帧上，您都应在 timer 或 profiler 对象上发出 \c start() 来指示帧的开始（\c process() 函数的开始）
- 使用 profiler，在 \c process() 函数中的各个检查点发出 \c checkpoint() 命令
- 在进程结束时，发出 \c stop() 命令

timer and profiler 类将累计 100 帧的平均统计数据，并会不时显示这些数据。我们不会在每一帧上都显示这些数据，因为这会减慢我们的速度，尤其是通过串行端口发送这些报告时。

让我们首先包含 profiler 声明以便我们可以使用它：

\code
#include <jevois/Debug/Profiler.H>
\endcode


让我们使用 jevois::Profiler 来检测我们的 \c process() 函数，如下所示。下面的新行都包含单词 \b prof ，请查找它，我们还添加了一些 <code>////////////////////////////////////////////////////////////</code> 标记来提供帮助：


\code
    void process(jevois::InputFrame && inframe) override
    {
      static jevois::Profiler prof("surpriserecorder");  ////////////////////////////////////////////////////////

       // Wait for next available camera image:
      jevois::RawImage inimg = inframe.get(); unsigned int const w = inimg.width, h = inimg.height;
      inimg.require("input", w, h, V4L2_PIX_FMT_YUYV); // accept any image size but require YUYV pixels

      prof.start(); ////////////////////////////////////////////////////////
      
      // Compute surprise in a thread:
      std::future<double> itsSurpFut =
        std::async(std::launch::async, [&]() { return itsSurprise->process(inimg); } );

      prof.checkpoint("surprise launched"); ////////////////////////////////////////////////////////
 
      // Convert the image to OpenCV BGR and push into our context buffer:
      cv::Mat cvimg = jevois::rawimage::convertToCvBGR(inimg);
      itsCtxBuf.push_back(cvimg);
      if (itsCtxBuf.size() > ctxframes::get()) itsCtxBuf.pop_front();
      
      prof.checkpoint("image pushed"); ////////////////////////////////////////////////////////

      // Wait until our surprise thread is done:
      double surprise = itsSurpFut.get(); // this could throw and that is ok
      //LINFO("surprise = " << surprise << " itsToSave = " << itsToSave);
      
      prof.checkpoint("surprise done"); ////////////////////////////////////////////////////////

      // Let camera know we are done processing the raw input image:
      inframe.done();

      // If the current frame is surprising, check whether we are already saving. If so, just push the current frame for
      // saving and reset itsToSave to full context length (after the event). Otherwise, keep saving until the context
      // after the event is exhausted:
      if (surprise >= thresh::get())
      {
        // Draw a rectangle on surprising frames. Note that we draw it in cvimg but, since the pixel memory is shared
        // with the copy of it we just pushed into itsCtxBuf, the rectangle will get drawn in there too:
        cv::rectangle(cvimg, cv::Point(3, 3), cv::Point(w-4, h-4), cv::Scalar(0,0,255), 7);
        
        if (itsToSave)
        {
          // we are still saving the context after the previous event, just add our new one:
          itsBuf.push(cvimg);

          // Reset the number of frames we will save after the end of the event:
          itsToSave = ctxframes::get();
        }
        else
        {
          // Start of a new event. Dump the whole itsCtxBuf to the writer:
          for (cv::Mat const & im : itsCtxBuf) itsBuf.push(im);

          // Initialize the number of frames we will save after the end of the event:
          itsToSave = ctxframes::get();
        }
      }
      else if (itsToSave)
      {
        // No more surprising event, but we are still saving the context after the last one:
        itsBuf.push(cvimg);

        // One more context frame after the last event was saved:
        --itsToSave;

        // Last context frame after the event was just pushed? If so, push an empty frame as well to close the current
        // video file. We will open a new file on the next surprising event:
        if (itsToSave == 0) itsBuf.push(cv::Mat());
      }

      prof.stop(); ////////////////////////////////////////////////////////
    }
\endcode


现在，每 100 帧，你将看到类似这样的内容：

\verbatim
INF Profiler::stop: surpriserecorder overall average (100) duration 15.4445ms [11.2414ms .. 22.1041ms] (64.7478 fps)
INF Profiler::stop: surpriserecorder - surprise launched average (100) delta duration 43.7507us [27.532us .. 77.293us] (22856.8 fps)
INF Profiler::stop: surpriserecorder - image pushed average (100) delta duration 950.279us [501.272us .. 1.96373ms] (1052.32 fps)
INF Profiler::stop: surpriserecorder - surprise done average (100) delta duration 14.4426ms [10.6092ms .. 20.9499ms] (69.2396 fps)
\endverbatim

总体平均值是从 \c start() 到 \c stop() 的时间。其他的是检查点，它们报告从开始到第一个检查点的时间，然后从第一个检查点到第二个检查点的时间，等等。显示的持续时间取决于主机的速度。

在主机上这不是很有用，所以现在一切似乎都运行良好，让我们在 JeVois 相机上运行这个 puppy。

编译并安装到 JeVois 智能相机 
-----------------------------------------------

我们基本上遵循标准编译说明（参见\ref FlashingToSD ）。

<ul>

<li> 在这里，我们将首先对 JeVois 平台硬件的所有内容进行完整的交叉重新编译，但这可能并不总是必要的。

\verbatim
cd ~/jevois && ./rebuild-platform.sh
cd ~/jevoisbase && ./rebuild-platform.sh --microsd
sudo jevois-flash-card -y /dev/sdX
\endverbatim

确保将上面的 \b sdX 替换为您的 microSD 设备。</li>


<li>写入 microSD 卡后，将其插入 JeVois 相机，将相机连接到主机，然后启动。请勿启动视频捕获软件。</li>

<li>通过串行终端（参见 \ref UserCli ）使用串行 USB 连接连接到 JeVois。然后发出以下命令：

\verbatim
help
info
setpar serlog USB
setpar serout USB
setmapping2 YUYV 640 480 15.0 JeVois SurpriseRecorder
setpar thresh 1e7
setpar channels S
streamon
\endverbatim

每隔几秒您就会看到这些消息：
\verbatim
INF Profiler::stop: surpriserecorder overall average (100) duration 68.4739ms [63.6285ms .. 83.3681ms] (14.6041 fps)
INF Profiler::stop: surpriserecorder - surprise launched average (100) delta duration 114.16us [102.125us .. 200.25us] (8759.64 fps)
INF Profiler::stop: surpriserecorder - image pushed average (100) delta duration 3.93424ms [2.97025ms .. 6.0565ms] (254.179 fps)
INF Profiler::stop: surpriserecorder - surprise done average (100) delta duration 64.4076ms [59.4994ms .. 79.3229ms] (15.5261 fps)
\endverbatim

现在在摄像机前挥手，你应该会得到一些 
\verbatim
SAVETO /jevois/data/surpriserecorder/video000000.avi
SAVEDNUM 100
SAVEDNUM 200
[...]
SAVEDONE /jevois/data/surpriserecorder/video000000.avi
\endverbatim

录制完一系列事件后，拔下 JeVois，取出 microSD，将其连接到主机，然后查看保存到其中的视频！

从分析器来看，我们猜测能够在 640x480 下实现 15fps 的效果似乎相当不错（参见总体平均报告）。

</li>

</ul>

使用预存数据微调你的算法 
----------------------------------------------

有时，能够在预先录制的视频序列上运行算法来对其进行微调是很有用的。例如，我们可能希望使用始终相同的数据以系统的方式调整算法的阈值、更新因子、通道。JeVois 框架允许这样做，只需在启动 \c jevois-daemon 时将视频文件指定为 \p cameradev（参见 \ref JeVoisDaemon ）。

在这里，我们将使用一段长达一小时的 320x240 视频，该视频是几年前作为现已停用的 blueservo 项目的一部分在网上实时发布的。这些摄像机正在德克萨斯州和墨西哥边境附近录制户外实时视频，并要求公民观看这些视频，如果发现任何可疑情况，请立即报警。

我们将在主机上进行测试。同样可以在 JeVois 上进行测试。

<ul> <li>首先，从 http://jevois.org/data/blueservo23_66.asf 下载测试视频

观看此视频，了解处理过程为何如此困难，因为：
+ 摄像机输入噪声。
+ 天空中移动的云会随时间投射出不同类型的大型移动阴影（快进观看影片即可看到）。
+ 树叶在风中摇曳，河面上偶尔泛起涟漪。


\youtube{aSKncW7Jxrs}

是的，这段视频<em>整整一个小时都很无聊！</em>但它确实包含一些简短有趣的事件，正如我们将在下面看到的。

</li>

<li>然后，在主机的 <b>/jevois/config/videomapping.cfg</b> 中创建一个新条目，以便我们可以立即开始使用我们的意外录音机模块：

\verbatim
NONE 0 0 0.0 YUYV 320 240 70.0 JeVois SurpriseRecorder
\endverbatim

或者，使用 \jvversion{1.3} 及更高版本，您只需在 Linux 终端中输入：
\verbatim
sudo jevois-add-videomapping NONE 0 0 0.0 YUYV 320 240 70.0 JeVois SurpriseRecorder
\endverbatim


这里我们假设您的主机足够快，可以以 70fps 和 320x240 的速度运行我们的意外模块。</li>

<li>在主机上运行 \c jevois-daemon （连接摄像头），然后输入 \c listmappings ，并记下分配给您刚刚创建的映射的映射编号。对于我们来说，该编号为 0。</li>

<li>现在编辑 <b>/jevois/config/initscript.cfg</b>：
\verbatim
setmapping 0
setpar serout All
setpar thresh 2.0e7
setpar ctxframes 75
setpar channels S
\endverbatim

请注意，我们使用了高阈值，因此我们得到的事件非常少。我们还将上下文减少到 +/- 5 秒（75 帧）。目前，我们还只计算显着性图上的意外，而不是要点或其他特征图上的意外。这需要更多的实验。

</li>

<li>最后，运行

\verbatim
jevois-daemon --cameradev=blueservo23_66.asf
\endverbatim

并让它过去。观看从这段长达一小时的视频中提取的事件。

\note 目前，当使用视频文件作为输入时，我们会无限循环输入（以模拟永无止境的实时馈送）。因此，请检查重复保存的剪辑，然后暂时中断 \c jevois-daemon 。将来某一天，JeVois 核心可能会改变这一点。

结果如下：

\youtube{zIslIsHBfYw}


</li>


</ul>


其他活动 
---------------------

您可以向该模块添加以下内容：

- 进一步调整参数：更新因子、通道、显著性参数等，并得出更好的默认值。

- 绘制最令人意外的位置（将所有内容重新映射到一维数据数组中，这可能会很棘手）。

- 添加带有视频输出的 \c process() 函数，可能显示最令人意外的位置以及绘制其意外程度和当前意外阈值的条形图。

- 保存事件的时间。请注意，JeVois 没有实时时钟。它在启动时总是初始化为 1979 年 12 月 31 日或类似的时间。在 JeVois 核心的未来版本中，我们可能会添加一个命令，允许从主机设置时间，以便录制的视频文件的时间戳是真实的。

- 在 Itti & Baldi, 2009 中，我们实际上以两种方式计算意外：随空间变化和随时间变化。在本教程中，我们只随时间变化。您也可以添加空间意外。

- 同样，在 Itti & Baldi, 2009 中，我们计算了 5 个不同时间尺度的意外，而这里我们只使用了一个。这也可以添加。

- 对于应以浮点数还是双精度数进行计算的一些优化可以使实际的意外计算更快。


*/

