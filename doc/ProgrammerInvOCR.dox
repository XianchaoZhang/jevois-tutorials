/*! \page ProgrammerInvOCR 使用 OpenCV 和 Tesseract 读取文本

本教程开发了一个简单的模块，该模块利用 JeVois 通过 OpenCV 和 Tesseract 库支持的光学字符识别 (OCR)，可通过 OpenCV Text 模块（包括 Python）获得。

方法
-----

- 我们需要了解如何使用 Tesseract 作为后端在 OpenCV 中执行字符识别。

- 我们将从相机传感器抓取图像，读取其中的文本，并在捕获图像下方的一小块区域中显示解码后的文本。为此，我们将创建一个复合输出显示，如 \ref ProgrammerInvComposite 中所示

创建模块
-------------------

- 从 JeVois Inventor 的下拉菜单中选择<b>新建 Python 模块...</b>（或按 `CTRL-N`）。

- 填写如下所示的详细信息：
  
  \jvimg{tesseract1.png, 40%} 
  
  因此，我们决定在输入图像下方留出一个 60 像素高的区域，我们将在其中写入解码后的文本。

- 允许 JeVois 重新启动，从 <b>Vision Module</b> 下拉菜单中选择新模块，然后切换到 Inventor 的 <b>Code</b> 选项卡。

编写代码 
----------------

在网上搜索 \a OpenCV 和 \a Tesseract 可以让我们找到 https://docs.opencv.org/3.4/d7/ddc/classcv_1_1text_1_1OCRTesseract.html，我们将使用它来运行我们的代码。

基本上，我们需要创建一个 OCR 对象（我们只需创建一次，因此我们将在模块的构造函数中执行此操作），然后我们将使用图像和置信度作为输入对其调用 `run()`，从而获得解码后的文本（如果有）。我们最终可以将该文本发送到串行并将其写入我们的输出显示。

首先，让我们完成 OCR 部分，只需将解码后的文本发送到串行端口即可。然后我们稍后再考虑制作复合显示器。

\code{.py}
import libjevois as jevois
import cv2
import numpy as np

class TesseractOCR:
    def __init__(self):
        self.ocr = cv2.text.OCRTesseract_create()
        
    def process(self, inframe, outframe):
        img = inframe.getCvBGR()
        txt = cv2.text_OCRTesseract.run(self.ocr, img, 50)
        jevois.sendSerial('TXT {}'.format(txt))
        outframe.sendCv(img)
\endcode

在 Inventor 的 \b Console 选项卡中启用<b>模块输出</b>到 \b USB ，然后……一切正常！

\jvimg{tesseract4.png, 70%}

\note 请注意，OpenCV OCR 模块旨在（据我们了解）在小型、预分割的框上运行，每个框可能只包含一个单词和最少的周围垃圾。这通常由负责查找和提取这些框的一些 <em>scene text</em> 算法完成。在这里，我们绕过此步骤，只将整个图像发送到 OCR。因为：
- 算法非常慢，因为我们处理整个 320x240 图像
- 如果出现多个单词，输出将显示它们连接成一个
- 如果存在垃圾，则可能将其解码为文本（如上面的日志所示：通常 Robotics 单词下方的垃圾标记被解码成某种东西，成功率各不相同...

添加复合显示输出 
-----------------------------------

现在，我们只需添加几行代码，将解码后的文本渲染到视频帧下方的小消息区域中，并将两个图像堆叠起来，如 \ref ProgrammerInvComposite

\code{.py}
import libjevois as jevois
import cv2
import numpy as np

class TesseractOCR:
    def __init__(self):
        self.ocr = cv2.text.OCRTesseract_create()
        
    def process(self, inframe, outframe):
        img = inframe.getCvBGR()
        txt = cv2.text_OCRTesseract.run(self.ocr, img, 50)
        jevois.sendSerial('TXT {}'.format(txt))
        msgbox = np.zeros((60, img.shape[1], 3), dtype = np.uint8) + 80
        cv2.putText(msgbox, txt, (3, 40), cv2.FONT_HERSHEY_SIMPLEX,
          0.8, (255,255,255), 2, cv2.LINE_AA)
        out = np.vstack((img, msgbox))
        outframe.sendCv(out)
\endcode

Here we go!

\jvimg{tesseract2.png, 70%}

\jvimg{tesseract3.png, 70%}


进一步 
-------------

如上所述，通过实现一个管道，首先提取每个单词周围的候选框，然后将每个框发送到 OCR（可以在多个框上并行化），将获得更好的结果。

例如，请参阅 https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/end_to_end_recognition.cpp （但它是用 C++ 编写的，因此如果需要，需要做一些工作才能转换成 python）。

*/

